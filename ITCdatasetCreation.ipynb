{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c02529",
   "metadata": {},
   "source": [
    "#                             __ITC GroceryProducts Dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52015e1",
   "metadata": {},
   "source": [
    "## Importing libraries \n",
    "\n",
    "### 1. Requests for Downloading webpages\n",
    "###  2. BeautifulSoup to parse the Downloaded Pages\n",
    "###  3.Pandas for creating Dataframes and Dictionaries\n",
    "###  4.OS module provides allows you to interface with the underlying operating system that Python is running  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bec502",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b763be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127c262b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2cde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d1f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2860fe1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (from pandas) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jahaa\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "067b6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b38752",
   "metadata": {},
   "source": [
    "#  scrape_food Funtion\n",
    "\n",
    "### 1.) Downloads the Page nessessary to get all the food available on the page \n",
    "### 2.) Parse the downloaded text data using selectors in final_all method of BeautifulSoup\n",
    "### 3.) Gather All information of titles of food and url in seperate lists\n",
    "### 4.) Create and return a DataFrame From the Dictionary Generated using Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf11a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_food():\n",
    "    front_url ='https://www.bing.com/aclk?ld=e8mIYpSFjSjwpGeLG1TSi7JTVUCUyKi2rH_2vxLmj0fyEOO1vtxELcQUmUDHO0jqaHAt6tcthc4mzi9-PMrcW9apR_bwLNJ6SnsmXBtIGEoK_OsyZZVGMhRX5rm45Di66VHTLaBE8XVpZ5TOPpIytPxaSmYE8hiiby5X0hxpvvatDgHKAWNaVlxZDdSUan2OwIxMlBvA&u=aHR0cHMlM2ElMmYlMmZpdGNzdG9yZS5pbiUzZnV0bV9zb3VyY2UlM2RiaW5nJTI2dXRtX21lZGl1bSUzZGNwYyUyNnV0bV9jYW1wYWlnbiUzZENYX0lUQ19pdGNzdG9yZV9HZW5lcmljX0NvcmVfR3JvY2VyeV8wOTIwMjElMjZ1dG1fY29udGVudCUzZEdyb2NlcnlfT25saW5lJTI2dXRtX3Rlcm0lM2RvbmxpbmUlMjUyMGdyb2NlcnklMjZtc2Nsa2lkJTNkNWNhNWMzOTMzYjZmMWJhMGU2N2NhMmQxMjcyMjhmNGY&rlid=5ca5c3933b6f1ba0e67ca2d127228f4f'\n",
    "    response = requests.get(front_url)\n",
    "    page_content = response.text\n",
    "    doc = BeautifulSoup(page_content,'html.parser')\n",
    "    selection_class = 'menu-lv-3'\n",
    "    li_tags= doc.find_all('li',class_=selection_class)\n",
    "    base_link = 'https://itcstore.in'\n",
    "    food_titles=[]\n",
    "    food_link = []\n",
    "    for tags in li_tags:\n",
    "        food_titles.append(tags.text.strip())\n",
    "    for tags in li_tags:\n",
    "        a_tags = tags.find_all('a')\n",
    "        href_tags = base_link+a_tags[0][\"href\"]+'/india-products'\n",
    "        food_link.append(href_tags)\n",
    "    food_dict = {\n",
    "        'title':food_titles,\n",
    "        'url':food_link\n",
    "    }\n",
    "    return pd.DataFrame(food_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597f43c",
   "metadata": {},
   "source": [
    "# get_food_page Function\n",
    "\n",
    "### 1.) Funtions To get All the products link of the Respective Food\n",
    "\n",
    "# scrape_products Function\n",
    "\n",
    "###   1.)It takes path to which csv files to get downloaded and Food link to generate The entire DataFrame of \n",
    "\n",
    "###    Title , No of Reviews and Sale Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e460ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_page(food_link):\n",
    "    response = requests.get(food_link)\n",
    "    page_content = response.text\n",
    "    doc2 = BeautifulSoup(page_content,'html.parser')\n",
    "    product_link = []\n",
    "    for tags in product_tag:\n",
    "        final_product_tag = base_link+tags['href']\n",
    "        product_link.append(final_product_tag)\n",
    "    return product_link\n",
    "def scrape_products(food_link,path):\n",
    "    products_df = get_product_info(get_food_page(food_link))\n",
    "    products_df.to_csv(path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe6faf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_product_info(product_link):\n",
    "        product_dict ={\n",
    "                'Titles': [],\n",
    "                'No of review':[],\n",
    "                'Price' :[]\n",
    "\n",
    "            }\n",
    "        for tags in product_link:  \n",
    "            response = requests.get(tags)\n",
    "            page_content = response.text\n",
    "            doc2 = BeautifulSoup(page_content,'html.parser')\n",
    "            \n",
    "\n",
    "            star_selector = \"jdgm-prev-badge__text\"\n",
    "            star_tags = doc2.find('span',class_=star_selector)\n",
    "            title_selector = 'product-title'\n",
    "            title_tags = doc2.find('h1',class_=title_selector)\n",
    "            sale_price_selector = 'price-se'\n",
    "            sale_price_tags = doc2.find('span',class_=sale_price_selector)\n",
    "            product_dict['Titles'].append(title_tags.text.strip())\n",
    "            product_dict['No of review'].append(star_tags.text.strip())\n",
    "            product_dict['Price'].append(sale_price_tags.text.strip())\n",
    "        return pd.DataFrame(product_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e5b19",
   "metadata": {},
   "source": [
    "#  scrape_food_products Function\n",
    "\n",
    "###  the following funtion traverse over DataFrame of food and for each food provides csv file of all products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "181f3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_food_products():\n",
    "    print('Scraping list of topics')\n",
    "    topics_df = scrape_food()\n",
    "    \n",
    "    os.makedirs('data2', exist_ok=True)\n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping Products for \"{}\"'.format(row['title']))\n",
    "        scrape_products(row['url'], 'data2/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d82c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13313405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping Products for \"Sunfeast Marie Light\"\n",
      "Scraping Products for \"Sunfeast Dark Fantasy\"\n",
      "Scraping Products for \"Sunfeast Farmlite\"\n",
      "Scraping Products for \"Sunfeast Bounce\"\n",
      "Scraping Products for \"Sunfeast Caker\"\n",
      "Scraping Products for \"Sunfeast Mom's Magic\"\n",
      "Scraping Products for \"Sunfeast All Rounder\"\n",
      "Scraping Products for \"Sunfeast YiPPee! Pasta\"\n",
      "Scraping Products for \"Sunfeast YiPPee! Noodles\"\n",
      "Scraping Products for \"Aashirvaad Atta\"\n",
      "Scraping Products for \"Aashirvaad Spices\"\n",
      "Scraping Products for \"Aashirvaad Masalas\"\n",
      "Scraping Products for \"Aashirvaad Iodised Salt\"\n",
      "Scraping Products for \"Aashirvaad Organic Atta and Dals\"\n",
      "Scraping Products for \"ITC Master Chef Cooking Paste\"\n",
      "Scraping Products for \"Cooking Ingredients\"\n",
      "Scraping Products for \"ITC Master Chef All-Purpose Gravies\"\n",
      "Scraping Products for \"Sunrise Pure\"\n",
      "Scraping Products for \"Bingo! Mad Angles\"\n",
      "Scraping Products for \"Bingo! Original Style\"\n",
      "Scraping Products for \"Bingo! Potato Chips\"\n",
      "Scraping Products for \"Bingo! Tedhe Medhe\"\n",
      "Scraping Products for \"B Natural\"\n",
      "Scraping Products for \"Sunbean Gourmet Coffee\"\n",
      "Scraping Products for \"Sunbean Beaten Caffe\"\n",
      "Scraping Products for \"Sunfeast Milkshakes\"\n",
      "Scraping Products for \"Aashirvaad Svasti Ghee\"\n",
      "Scraping Products for \"Aashirvaad Svasti Milk Products\"\n",
      "Scraping Products for \"Kitchens of India\"\n",
      "Scraping Products for \"Aashirvaad Instant Meals\"\n",
      "Scraping Products for \"ITC Master Chef Spreads & Dips\"\n",
      "Scraping Products for \"Jelimals\"\n",
      "Scraping Products for \"Candyman Fantastik\"\n",
      "Scraping Products for \"Candyman Choco Double Eclairs\"\n",
      "Scraping Products for \"Fabelle Chocolates\"\n",
      "Scraping Products for \"Fabelle Luxury Chocolates\"\n",
      "Scraping Products for \"ITC Master Chef Frozen Snacks\"\n",
      "Scraping Products for \"ITC Master Chef Frozen Prawns\"\n",
      "Scraping Products for \"Farmland Frozen Vegetables\"\n",
      "Scraping Products for \"Antiseptic Liquid\"\n",
      "Scraping Products for \"Body wash\"\n",
      "Scraping Products for \"Surface Disinfectant Spray\"\n",
      "Scraping Products for \"Clothes Disinfectant Spray\"\n",
      "Scraping Products for \"FFP2 S Masks\"\n",
      "Scraping Products for \"Germ Protection Wipes\"\n",
      "Scraping Products for \"Hand Sanitizer\"\n",
      "Scraping Products for \"Handwash\"\n",
      "Scraping Products for \"Savlon Laundry Disinfectant\"\n",
      "Scraping Products for \"Home Cleaners\"\n",
      "Scraping Products for \"Soaps\"\n",
      "Scraping Products for \"Creams\"\n",
      "Scraping Products for \"Facewash\"\n",
      "Scraping Products for \"Serum\"\n",
      "Scraping Products for \"Hand Cream\"\n",
      "Scraping Products for \"Anti Ageing\"\n",
      "Scraping Products for \"Body Care\"\n",
      "Scraping Products for \"Cleanser\"\n",
      "Scraping Products for \"Face Mask\"\n",
      "Scraping Products for \"Hydration\"\n",
      "Scraping Products for \"Skin Toner\"\n",
      "Scraping Products for \"Sun Care\"\n",
      "Scraping Products for \"Cologne\"\n",
      "Scraping Products for \"Deodorant\"\n",
      "Scraping Products for \"L'amante & Premium Perfume\"\n",
      "Scraping Products for \"Perfume Spray\"\n",
      "Scraping Products for \"Pocket Perfume\"\n",
      "Scraping Products for \"Luxury Perfume\"\n",
      "Scraping Products for \"Luxury Deodorant\"\n",
      "Scraping Products for \"Luxury Soaps\"\n",
      "Scraping Products for \"Body wash & Shower Gel\"\n",
      "Scraping Products for \"Handwash\"\n",
      "Scraping Products for \"Soaps\"\n",
      "Scraping Products for \"Dishwash Liquid\"\n",
      "Scraping Products for \"Vegetable & Fruit Wash\"\n",
      "Scraping Products for \"Floor Cleaner\"\n",
      "Scraping Products for \"Talc\"\n",
      "Scraping Products for \"Vivel Body wash\"\n",
      "Scraping Products for \"Vivel Soaps\"\n",
      "Scraping Products for \"Aashirvaad Atta\"\n",
      "Scraping Products for \"B Natural\"\n",
      "Scraping Products for \"Bingo! Potato Chips\"\n",
      "Scraping Products for \"Sunfeast YiPPee! Pasta\"\n",
      "Scraping Products for \"Aashirvaad Svastighee\"\n",
      "Scraping Products for \"Sunfeast YiPPee! Noodles\"\n",
      "Scraping Products for \"Bingo! Mad Angles\"\n",
      "Scraping Products for \"Sunfeast Dark Fantasy\"\n",
      "Scraping Products for \"Aashirvaad Iodised Salt\"\n",
      "Scraping Products for \"Aashirvaad Spices\"\n",
      "Scraping Products for \"Aashirvaad  Instant  Mixes\"\n",
      "Scraping Products for \"Bingo! Original Style\"\n",
      "Scraping Products for \"Bingo! Tedhe Medhe\"\n",
      "Scraping Products for \"Sunfeast Marie Light\"\n",
      "Scraping Products for \"Kitchens Of India\"\n",
      "Scraping Products for \"Sunfeast Bounce\"\n",
      "Scraping Products for \"Fabelle Chocolates\"\n",
      "Scraping Products for \"Candyman ChocoDouble Eclairs\"\n",
      "Scraping Products for \"Sunfeast Farmlite\"\n",
      "Scraping Products for \"Fabelle luxury Chocolates\"\n",
      "Scraping Products for \"Candyman Fantastik\"\n",
      "Scraping Products for \"Jelimals\"\n",
      "Scraping Products for \"Sunfeast Milkshakes\"\n",
      "Scraping Products for \"Sunbean GourmetCoffee\"\n",
      "Scraping Products for \"ITC Master Chef Cooking paste\"\n",
      "Scraping Products for \"ITC Master Chef  Frozen Snacks\"\n",
      "Scraping Products for \"ITC Masterchef  Frozen Prawns\"\n",
      "Scraping Products for \"Farmland Frozen  Vegetables\"\n",
      "Scraping Products for \"Sunbean Beaten Caffe\"\n",
      "Scraping Products for \"Aashirvaad Masalas\"\n",
      "Scraping Products for \"Aashirvaad Instant   Meals\"\n",
      "Scraping Products for \"Aashirvaad OrganicAtta and Dals\"\n",
      "Scraping Products for \"ITC Master Chef  Spreads & Dips\"\n",
      "Scraping Products for \"Cooking Ingredients\"\n",
      "Scraping Products for \"ITC Master Chef All-Purpose Gravies\"\n",
      "Scraping Products for \"Sunrise Pure\"\n",
      "Scraping Products for \"Sunfeast Caker\"\n",
      "Scraping Products for \"Sunfeast Mom's Magic\"\n",
      "Scraping Products for \"Aashirvaad Svasti Milk Products\"\n",
      "Scraping Products for \"Sunfeast All Rounder\"\n",
      "Scraping Products for \"Fiama\"\n",
      "Scraping Products for \"Savlon\"\n",
      "Scraping Products for \"Charmis\"\n",
      "Scraping Products for \"Nimyle\"\n",
      "Scraping Products for \"Engage\"\n",
      "Scraping Products for \"Essenza Di Wills\"\n",
      "Scraping Products for \"Vivel\"\n",
      "Scraping Products for \"Dermafique\"\n",
      "Scraping Products for \"Nimwash\"\n",
      "Scraping Products for \"Shower to Shower\"\n",
      "Scraping Products for \"Nimeasy\"\n",
      "Scraping Products for \"Classmate\"\n",
      "Scraping Products for \"PaperKraft\"\n",
      "Scraping Products for \"Homelites\"\n",
      "Scraping Products for \"Mangaldeep\"\n"
     ]
    }
   ],
   "source": [
    "scrape_food_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8816cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
